{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BootCamp-BMA/colabs/blob/main/dziriBertRandomSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS5eEsO9oHnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcac387-8a11-455c-d516-b5cb892a2d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Imported all required libraries\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Imported all required libraries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raBfFmyhvsfJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_and_visualize_data(file_path):\n",
        "    \"\"\"Load dataset.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNKBP6_YvsfK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_and_tokenize_data(df, tokenizer_name='alger-ia/dziribert', max_length=128, test_size=0.2, random_state=42):\n",
        "    \"\"\"Split data into train/test and tokenize using DziriBERT tokenizer.\"\"\"\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df['news'].tolist(),\n",
        "        df['label'].tolist(),\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n",
        "    train_tokens = tokenizer(train_texts, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    test_tokens = tokenizer(test_texts, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    test_labels = torch.tensor(test_labels)\n",
        "    return train_tokens, test_tokens, train_labels, test_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkoOxSf6vsfM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_dataloaders(train_tokens, test_tokens, train_labels, test_labels, batch_size=16):\n",
        "    \"\"\"Create DataLoaders for training and testing.\"\"\"\n",
        "    train_data = TensorDataset(train_tokens['input_ids'], train_tokens['attention_mask'], train_labels)\n",
        "    test_data = TensorDataset(test_tokens['input_ids'], test_tokens['attention_mask'], test_labels)\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    return train_dataloader, test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CW-ZqNavsfM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def setup_model_and_device(model_name='alger-ia/dziribert', num_labels=2, layer_control=None):\n",
        "    \"\"\"Set up DziriBERT model and device, with optional layer control.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    model.to(device)\n",
        "    if layer_control:\n",
        "        for i, layer in enumerate(model.bert.encoder.layer):\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = layer_control.get(i, False)\n",
        "    return model, device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvNQMcfovsfN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def setup_training_components(model, train_dataloader, num_epochs=5, lr=2e-5, class_weights=[2.0, 1.0], device=None):\n",
        "    \"\"\"Set up optimizer, scheduler, and loss function.\"\"\"\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
        "    num_training_steps = len(train_dataloader) * num_epochs\n",
        "    lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "    class_weights = torch.tensor(class_weights).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return optimizer, lr_scheduler, criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lapkH3PDvsfO"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm  # Import tqdm\n",
        "\n",
        "def train_model(model, train_dataloader, optimizer, criterion, lr_scheduler, device, epochs=5):\n",
        "    \"\"\"Train the model with batch progress tracking per epoch.\"\"\"\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        # Wrap the batch loop with tqdm\n",
        "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=True)\n",
        "        for batch in progress_bar:\n",
        "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update progress bar with current loss\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "        avg_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Avg Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvCMA3sIvsfO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_model(model, test_dataloader, device):\n",
        "    \"\"\"Evaluate the model on test data.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    roc_auc = roc_auc_score(all_labels, all_preds)\n",
        "    return accuracy, roc_auc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hFY1mi5vsfP",
        "outputId": "354dba17-e772-4546-aa20-320b6a0aef45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 482/482 [00:37<00:00, 12.91it/s, loss=0.0861]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 482/482 [00:37<00:00, 12.93it/s, loss=0.0275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 482/482 [00:37<00:00, 12.92it/s, loss=0.0396]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0421\n",
            "Iteration: 1\n",
            "{'iteration': 1, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 7, 'max_length': 64, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(1, 2, 7, 8, 9, 10)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 268.41944122314453, 'accuracy': 0.7619294605809128, 'roc_auc': 0.7552466299436102}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [01:15<00:00, 12.82it/s, loss=0.774]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [01:15<00:00, 12.84it/s, loss=0.363]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [01:15<00:00, 12.82it/s, loss=1.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [01:15<00:00, 12.82it/s, loss=0.0163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [01:15<00:00, 12.82it/s, loss=0.000901]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0305\n",
            "Iteration: 2\n",
            "{'iteration': 2, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(0, 1, 6, 7, 9, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 386.8399770259857, 'accuracy': 0.7728215767634855, 'roc_auc': 0.768031365042768}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 241/241 [01:01<00:00,  3.93it/s, loss=0.188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 241/241 [01:01<00:00,  3.93it/s, loss=0.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 241/241 [01:01<00:00,  3.91it/s, loss=0.198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.0283]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 241/241 [01:01<00:00,  3.93it/s, loss=0.0118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 241/241 [01:01<00:00,  3.93it/s, loss=0.006]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0187\n",
            "Iteration: 3\n",
            "{'iteration': 3, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 7, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(0, 1, 3, 9)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 440.65004682540894, 'accuracy': 0.7728215767634855, 'roc_auc': 0.7660933447163932}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [01:27<00:00, 11.07it/s, loss=0.992]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [01:26<00:00, 11.09it/s, loss=0.385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [01:27<00:00, 11.08it/s, loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [01:26<00:00, 11.09it/s, loss=0.00247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [01:26<00:00, 11.09it/s, loss=0.0395]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0359\n",
            "Iteration: 4\n",
            "{'iteration': 4, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(1,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 445.65176820755005, 'accuracy': 0.7650414937759336, 'roc_auc': 0.7633445532602134}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 964/964 [01:19<00:00, 12.14it/s, loss=0.193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 964/964 [01:19<00:00, 12.15it/s, loss=0.366]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 964/964 [01:19<00:00, 12.13it/s, loss=0.744]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 964/964 [01:19<00:00, 12.13it/s, loss=0.00456]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 964/964 [01:19<00:00, 12.13it/s, loss=0.0014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 964/964 [01:19<00:00, 12.13it/s, loss=0.000134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 964/964 [01:19<00:00, 12.14it/s, loss=9.92e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0132\n",
            "Iteration: 5\n",
            "{'iteration': 5, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 7, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(6, 8, 9, 10)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 566.906229019165, 'accuracy': 0.7603734439834025, 'roc_auc': 0.7564195563869297}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.564]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 241/241 [01:05<00:00,  3.68it/s, loss=0.344]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.3896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.2666\n",
            "Iteration: 6\n",
            "{'iteration': 6, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 3, 'max_length': 128, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(1,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 207.4040629863739, 'accuracy': 0.7697095435684648, 'roc_auc': 0.7562727366652348}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [02:29<00:00,  6.46it/s, loss=0.459]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [02:29<00:00,  6.46it/s, loss=0.871]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [02:29<00:00,  6.46it/s, loss=0.00775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [02:29<00:00,  6.46it/s, loss=0.00555]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [02:29<00:00,  6.46it/s, loss=0.00066]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0355\n",
            "Iteration: 7\n",
            "{'iteration': 7, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 256, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(8,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 763.9160466194153, 'accuracy': 0.7754149377593361, 'roc_auc': 0.7694141893104367}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 964/964 [01:15<00:00, 12.80it/s, loss=1.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 964/964 [01:15<00:00, 12.84it/s, loss=0.271]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 964/964 [01:15<00:00, 12.83it/s, loss=0.00299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 964/964 [01:15<00:00, 12.82it/s, loss=0.0014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 964/964 [01:15<00:00, 12.84it/s, loss=0.0434]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 964/964 [01:15<00:00, 12.81it/s, loss=0.000893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 964/964 [01:15<00:00, 12.84it/s, loss=0.000614]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0139\n",
            "Iteration: 8\n",
            "{'iteration': 8, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 7, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(1, 4, 5, 8, 10, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 537.3066146373749, 'accuracy': 0.7650414937759336, 'roc_auc': 0.7607605261583804}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [02:18<00:00,  6.96it/s, loss=0.637]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [02:18<00:00,  6.96it/s, loss=0.027]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [02:18<00:00,  6.97it/s, loss=0.0661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [02:18<00:00,  6.96it/s, loss=0.148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [02:18<00:00,  6.97it/s, loss=0.0014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0375\n",
            "Iteration: 9\n",
            "{'iteration': 9, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 256, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(1, 2, 4, 11)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 710.170351266861, 'accuracy': 0.7671161825726142, 'roc_auc': 0.7624266581112458}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 241/241 [01:01<00:00,  3.93it/s, loss=0.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.5502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 241/241 [01:01<00:00,  3.90it/s, loss=0.381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.4556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.389]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.3369\n",
            "Iteration: 10\n",
            "{'iteration': 10, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 1e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(3, 4, 6, 7)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 317.7694454193115, 'accuracy': 0.7359958506224067, 'roc_auc': 0.7304362720841332}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [02:12<00:00,  7.25it/s, loss=0.184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [02:12<00:00,  7.25it/s, loss=0.196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [02:13<00:00,  7.25it/s, loss=0.0989]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.2168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [02:12<00:00,  7.25it/s, loss=0.317]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.1162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [02:12<00:00,  7.25it/s, loss=0.0495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0726\n",
            "Iteration: 11\n",
            "{'iteration': 11, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(0, 3, 4, 6, 7, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 682.1273100376129, 'accuracy': 0.7567427385892116, 'roc_auc': 0.747312927204607}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [02:25<00:00,  6.62it/s, loss=0.777]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [02:25<00:00,  6.62it/s, loss=0.133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.4386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [02:25<00:00,  6.62it/s, loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.2717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [02:25<00:00,  6.61it/s, loss=0.0285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.1619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [02:25<00:00,  6.62it/s, loss=0.0991]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.1093\n",
            "Iteration: 12\n",
            "{'iteration': 12, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 256, 'learning_rate': 1e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(9, 10)', 'num_trainable_layers': 2, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 746.0682466030121, 'accuracy': 0.7738589211618258, 'roc_auc': 0.7663880717132774}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 482/482 [00:39<00:00, 12.20it/s, loss=0.488]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 482/482 [00:39<00:00, 12.16it/s, loss=0.375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.4562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 482/482 [00:39<00:00, 12.19it/s, loss=0.425]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.3477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 482/482 [00:39<00:00, 12.17it/s, loss=0.161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.2655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 482/482 [00:39<00:00, 12.22it/s, loss=0.226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.2146\n",
            "Iteration: 13\n",
            "{'iteration': 13, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 5, 'max_length': 64, 'learning_rate': 1e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(3, 6, 8, 11)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 204.7849771976471, 'accuracy': 0.7474066390041494, 'roc_auc': 0.7358316249680531}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 964/964 [02:15<00:00,  7.12it/s, loss=0.563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 964/964 [02:15<00:00,  7.12it/s, loss=0.215]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 964/964 [02:15<00:00,  7.12it/s, loss=0.144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 964/964 [02:15<00:00,  7.12it/s, loss=0.431]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 964/964 [02:15<00:00,  7.13it/s, loss=0.0193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 964/964 [02:15<00:00,  7.13it/s, loss=0.0114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 964/964 [02:15<00:00,  7.12it/s, loss=0.000454]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0239\n",
            "Iteration: 14\n",
            "{'iteration': 14, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 7, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(2, 3, 6, 7, 11)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 964.9430890083313, 'accuracy': 0.7671161825726142, 'roc_auc': 0.7612423123562391}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [01:22<00:00, 11.75it/s, loss=0.823]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.6273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [01:21<00:00, 11.77it/s, loss=0.0695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [01:21<00:00, 11.78it/s, loss=0.191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.3357\n",
            "Iteration: 15\n",
            "{'iteration': 15, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 128, 'learning_rate': 1e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(3, 5, 8)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 257.1941924095154, 'accuracy': 0.7437759336099585, 'roc_auc': 0.7420138228049092}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [02:15<00:00,  7.11it/s, loss=0.692]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.6031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [02:15<00:00,  7.10it/s, loss=0.184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.3978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [02:15<00:00,  7.10it/s, loss=0.0851]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.2324\n",
            "Iteration: 16\n",
            "{'iteration': 16, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(2, 3, 4, 6, 8)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 424.8686864376068, 'accuracy': 0.7660788381742739, 'roc_auc': 0.7610552531552646}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 241/241 [00:32<00:00,  7.39it/s, loss=0.447]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 241/241 [00:32<00:00,  7.37it/s, loss=0.659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 241/241 [00:32<00:00,  7.33it/s, loss=0.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 241/241 [00:33<00:00,  7.30it/s, loss=0.0885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 241/241 [00:32<00:00,  7.30it/s, loss=0.014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 241/241 [00:33<00:00,  7.29it/s, loss=0.00701]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 241/241 [00:33<00:00,  7.29it/s, loss=0.00207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0193\n",
            "Iteration: 17\n",
            "{'iteration': 17, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 7, 'max_length': 64, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(1, 2, 4, 6, 11)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 237.36687994003296, 'accuracy': 0.7712655601659751, 'roc_auc': 0.7634978983028727}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 482/482 [00:40<00:00, 11.91it/s, loss=0.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 482/482 [00:40<00:00, 11.89it/s, loss=0.171]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 482/482 [00:40<00:00, 11.92it/s, loss=0.239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 482/482 [00:40<00:00, 11.90it/s, loss=0.793]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 482/482 [00:40<00:00, 11.93it/s, loss=0.00564]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 482/482 [00:40<00:00, 11.92it/s, loss=0.0286]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 482/482 [00:40<00:00, 11.91it/s, loss=0.00196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0149\n",
            "Iteration: 18\n",
            "{'iteration': 18, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 7, 'max_length': 64, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(1, 6, 9)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 290.61433935165405, 'accuracy': 0.7795643153526971, 'roc_auc': 0.7721004464407093}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 482/482 [00:38<00:00, 12.52it/s, loss=0.509]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.4431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.2774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.1594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.0163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.1027\n",
            "Iteration: 19\n",
            "{'iteration': 19, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 5, 'max_length': 64, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(0, 3, 4, 6, 11)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 199.7041256427765, 'accuracy': 0.7671161825726142, 'roc_auc': 0.7630726648867041}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 482/482 [01:04<00:00,  7.51it/s, loss=0.737]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.6048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 482/482 [01:04<00:00,  7.50it/s, loss=0.507]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 482/482 [01:04<00:00,  7.42it/s, loss=0.441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.3405\n",
            "Iteration: 20\n",
            "{'iteration': 20, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 3, 'max_length': 128, 'learning_rate': 2e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(0, 2, 3, 5, 9, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 204.11483716964722, 'accuracy': 0.7349585062240664, 'roc_auc': 0.7396163111273035}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 482/482 [00:40<00:00, 11.87it/s, loss=0.628]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.6406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 482/482 [00:40<00:00, 11.85it/s, loss=0.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.4910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 482/482 [00:40<00:00, 11.91it/s, loss=0.392]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.3427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 482/482 [00:40<00:00, 11.88it/s, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 482/482 [00:40<00:00, 11.89it/s, loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.1565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 482/482 [00:40<00:00, 11.88it/s, loss=0.193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 482/482 [00:40<00:00, 11.90it/s, loss=0.0893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0873\n",
            "Iteration: 21\n",
            "{'iteration': 21, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 7, 'max_length': 64, 'learning_rate': 1e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(5, 10, 11)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 291.20489025115967, 'accuracy': 0.7588174273858921, 'roc_auc': 0.7535011065856803}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 964/964 [01:27<00:00, 11.05it/s, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 964/964 [01:27<00:00, 11.05it/s, loss=0.0909]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 964/964 [01:27<00:00, 11.03it/s, loss=0.183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 964/964 [01:27<00:00, 11.04it/s, loss=0.0348]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 964/964 [01:27<00:00, 11.04it/s, loss=0.000893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0380\n",
            "Iteration: 22\n",
            "{'iteration': 22, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(5,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 447.29387378692627, 'accuracy': 0.7754149377593361, 'roc_auc': 0.7722135520040893}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 241/241 [01:00<00:00,  3.95it/s, loss=0.592]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 241/241 [01:01<00:00,  3.92it/s, loss=0.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 241/241 [01:01<00:00,  3.91it/s, loss=0.449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.3298\n",
            "Iteration: 23\n",
            "{'iteration': 23, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 3, 'max_length': 128, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(7, 8, 9, 11)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 194.38501405715942, 'accuracy': 0.7297717842323651, 'roc_auc': 0.7119794017368228}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [00:50<00:00, 19.03it/s, loss=0.422]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [00:50<00:00, 19.04it/s, loss=0.356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.3710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [00:50<00:00, 18.98it/s, loss=0.0478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.1948\n",
            "Iteration: 24\n",
            "{'iteration': 24, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 64, 'learning_rate': 2e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(2, 4, 6, 10)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 158.99142718315125, 'accuracy': 0.7624481327800829, 'roc_auc': 0.7621770645843643}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 964/964 [02:12<00:00,  7.27it/s, loss=0.827]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.255]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.0416]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.2056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.0144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.1039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.000773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.266]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 964/964 [02:12<00:00,  7.26it/s, loss=0.0021]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0268\n",
            "Iteration: 25\n",
            "{'iteration': 25, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 7, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(0, 3, 7, 8, 9, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 947.0400605201721, 'accuracy': 0.7624481327800829, 'roc_auc': 0.7597007052784408}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 482/482 [02:01<00:00,  3.98it/s, loss=0.561]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.6077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 482/482 [02:01<00:00,  3.95it/s, loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.4302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 482/482 [02:01<00:00,  3.96it/s, loss=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.2537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 482/482 [02:01<00:00,  3.96it/s, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.1413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 482/482 [02:01<00:00,  3.96it/s, loss=0.0223]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 482/482 [02:01<00:00,  3.95it/s, loss=0.087]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 482/482 [02:01<00:00,  3.96it/s, loss=0.00184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0421\n",
            "Iteration: 26\n",
            "{'iteration': 26, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 7, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(3, 4, 5, 8, 10, 11)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 870.0362865924835, 'accuracy': 0.7567427385892116, 'roc_auc': 0.7546343373264671}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 482/482 [01:09<00:00,  6.97it/s, loss=0.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.6093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 482/482 [01:09<00:00,  6.95it/s, loss=0.385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.4698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 482/482 [01:09<00:00,  6.93it/s, loss=0.508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.3427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 482/482 [01:09<00:00,  6.94it/s, loss=0.158]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.2337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 482/482 [01:09<00:00,  6.94it/s, loss=0.0619]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 482/482 [01:09<00:00,  6.95it/s, loss=0.206]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.1254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 482/482 [01:09<00:00,  6.94it/s, loss=0.329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0995\n",
            "Iteration: 27\n",
            "{'iteration': 27, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 7, 'max_length': 128, 'learning_rate': 1e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(1, 4, 5)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 496.5348846912384, 'accuracy': 0.7546680497925311, 'roc_auc': 0.7522145308022338}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [00:52<00:00, 18.38it/s, loss=0.302]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [00:52<00:00, 18.41it/s, loss=0.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [00:52<00:00, 18.42it/s, loss=0.00917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.1076\n",
            "Iteration: 28\n",
            "{'iteration': 28, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 64, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(5, 10, 11)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 163.79389786720276, 'accuracy': 0.7785269709543569, 'roc_auc': 0.7707290414847281}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.423]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.3516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.277]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.1658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.0463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.0816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.0194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.00391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 241/241 [02:12<00:00,  1.82it/s, loss=0.051]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0172\n",
            "Iteration: 29\n",
            "{'iteration': 29, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 7, 'max_length': 256, 'learning_rate': 5e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(3, 6)', 'num_trainable_layers': 2, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 944.2103445529938, 'accuracy': 0.774896265560166, 'roc_auc': 0.7693744936079043}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [02:25<00:00,  6.60it/s, loss=0.511]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [02:25<00:00,  6.60it/s, loss=0.807]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [02:25<00:00,  6.61it/s, loss=0.329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.2940\n",
            "Iteration: 30\n",
            "{'iteration': 30, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 256, 'learning_rate': 1e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(3, 7)', 'num_trainable_layers': 2, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 455.6333649158478, 'accuracy': 0.7551867219917012, 'roc_auc': 0.7409491079342465}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.685]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.696]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.5050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.416]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.3967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 241/241 [01:05<00:00,  3.67it/s, loss=0.309]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.3100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 241/241 [01:05<00:00,  3.66it/s, loss=0.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.2603\n",
            "Iteration: 31\n",
            "{'iteration': 31, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 1e-05, 'class_weights': '[1.0, 2.0]', 'trainable_layers': '(7,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 338.69591999053955, 'accuracy': 0.7406639004149378, 'roc_auc': 0.7452210180588258}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 241/241 [00:31<00:00,  7.61it/s, loss=0.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.6443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 241/241 [00:32<00:00,  7.53it/s, loss=0.404]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 241/241 [00:31<00:00,  7.58it/s, loss=0.256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.3852\n",
            "Iteration: 32\n",
            "{'iteration': 32, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 3, 'max_length': 64, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(1, 5, 6, 7, 8, 10)', 'num_trainable_layers': 6, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 102.50586271286011, 'accuracy': 0.729253112033195, 'roc_auc': 0.7253981805230045}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.692]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.3988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.225]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.2686\n",
            "Iteration: 33\n",
            "{'iteration': 33, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 3, 'max_length': 64, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(1, 3, 4, 10, 11)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 123.27388525009155, 'accuracy': 0.7598547717842323, 'roc_auc': 0.7462590878688845}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 482/482 [01:06<00:00,  7.24it/s, loss=0.512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 482/482 [01:06<00:00,  7.23it/s, loss=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 482/482 [01:06<00:00,  7.21it/s, loss=0.288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.4082\n",
            "Iteration: 34\n",
            "{'iteration': 34, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 3, 'max_length': 128, 'learning_rate': 1e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(1, 3, 4, 6, 9)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 210.56858825683594, 'accuracy': 0.7074688796680498, 'roc_auc': 0.6840015443259615}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 964/964 [02:22<00:00,  6.78it/s, loss=0.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.5658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 964/964 [02:22<00:00,  6.78it/s, loss=0.105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.4328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 964/964 [02:22<00:00,  6.78it/s, loss=0.355]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.3396\n",
            "Iteration: 35\n",
            "{'iteration': 35, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 8, 'num_epochs': 3, 'max_length': 256, 'learning_rate': 1e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(0, 2, 9)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 444.59826922416687, 'accuracy': 0.7432572614107884, 'roc_auc': 0.7279773136341143}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 241/241 [00:34<00:00,  7.05it/s, loss=0.586]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Avg Loss: 0.6557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 241/241 [00:34<00:00,  7.02it/s, loss=0.586]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - Avg Loss: 0.5474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 241/241 [00:34<00:00,  7.06it/s, loss=0.562]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - Avg Loss: 0.4749\n",
            "Iteration: 36\n",
            "{'iteration': 36, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 3, 'max_length': 64, 'learning_rate': 1e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(2, 5, 10)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 109.3762526512146, 'accuracy': 0.7261410788381742, 'roc_auc': 0.7195612809205052}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 482/482 [01:09<00:00,  6.96it/s, loss=0.712]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 482/482 [01:09<00:00,  6.95it/s, loss=0.065]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 482/482 [01:09<00:00,  6.94it/s, loss=0.378]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 482/482 [01:09<00:00,  6.94it/s, loss=0.0446]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 482/482 [01:09<00:00,  6.95it/s, loss=0.0133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0390\n",
            "Iteration: 37\n",
            "{'iteration': 37, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 5e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(0, 1, 4)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 357.22591829299927, 'accuracy': 0.7712655601659751, 'roc_auc': 0.7674816067515321}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 482/482 [02:15<00:00,  3.56it/s, loss=0.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 482/482 [02:15<00:00,  3.55it/s, loss=0.134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 482/482 [02:15<00:00,  3.55it/s, loss=0.389]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.2016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 482/482 [02:15<00:00,  3.55it/s, loss=0.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.1003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 482/482 [02:15<00:00,  3.55it/s, loss=0.0131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0582\n",
            "Iteration: 38\n",
            "{'iteration': 38, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 5, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(2,)', 'num_trainable_layers': 1, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 696.1137125492096, 'accuracy': 0.770746887966805, 'roc_auc': 0.7645348805594375}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 241/241 [01:04<00:00,  3.75it/s, loss=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.6245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 241/241 [01:04<00:00,  3.76it/s, loss=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.4503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 241/241 [01:04<00:00,  3.75it/s, loss=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.2815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 241/241 [01:04<00:00,  3.75it/s, loss=0.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.1707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 241/241 [01:04<00:00,  3.75it/s, loss=0.157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.1162\n",
            "Iteration: 39\n",
            "{'iteration': 39, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 5, 'max_length': 128, 'learning_rate': 2e-05, 'class_weights': '[1.0, 1.0]', 'trainable_layers': '(2, 4)', 'num_trainable_layers': 2, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 331.45816826820374, 'accuracy': 0.7660788381742739, 'roc_auc': 0.7606245819716256}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 241/241 [00:33<00:00,  7.17it/s, loss=0.357]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 241/241 [00:33<00:00,  7.15it/s, loss=0.127]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 241/241 [00:33<00:00,  7.15it/s, loss=0.0325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 241/241 [00:33<00:00,  7.15it/s, loss=0.0261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 241/241 [00:33<00:00,  7.15it/s, loss=0.0323]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0370\n",
            "Iteration: 40\n",
            "{'iteration': 40, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 5, 'max_length': 64, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(1, 4, 7, 11)', 'num_trainable_layers': 4, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 175.31312894821167, 'accuracy': 0.7645228215767634, 'roc_auc': 0.7545837660889945}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Avg Loss: 0.5315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Avg Loss: 0.3196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.0221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Avg Loss: 0.1392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.0578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Avg Loss: 0.0672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 482/482 [00:38<00:00, 12.51it/s, loss=0.0011]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Avg Loss: 0.0330\n",
            "Iteration: 41\n",
            "{'iteration': 41, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 16, 'num_epochs': 5, 'max_length': 64, 'learning_rate': 5e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(0, 2, 6, 7, 10)', 'num_trainable_layers': 5, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 199.93034720420837, 'accuracy': 0.7702282157676349, 'roc_auc': 0.76266483232644}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7: 100%|██████████| 241/241 [02:09<00:00,  1.86it/s, loss=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 - Avg Loss: 0.5615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 241/241 [02:09<00:00,  1.85it/s, loss=0.366]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/7 - Avg Loss: 0.4186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 241/241 [02:09<00:00,  1.85it/s, loss=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/7 - Avg Loss: 0.2719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 241/241 [02:10<00:00,  1.85it/s, loss=0.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/7 - Avg Loss: 0.1547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 241/241 [02:09<00:00,  1.85it/s, loss=0.0483]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/7 - Avg Loss: 0.0992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 241/241 [02:09<00:00,  1.85it/s, loss=0.0871]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/7 - Avg Loss: 0.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 241/241 [02:09<00:00,  1.85it/s, loss=0.0113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 - Avg Loss: 0.0445\n",
            "Iteration: 42\n",
            "{'iteration': 42, 'dataset_path': '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv', 'dataset_size': 9636, 'batch_size': 32, 'num_epochs': 7, 'max_length': 256, 'learning_rate': 2e-05, 'class_weights': '[2.0, 1.0]', 'trainable_layers': '(7, 9, 11)', 'num_trainable_layers': 3, 'device': 'cuda', 'cuda_available': True, 'torch_version': '2.5.1+cu124', 'transformers_version': '4.48.3', 'execution_time': 927.8011448383331, 'accuracy': 0.766597510373444, 'roc_auc': 0.7570035726132279}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alger-ia/dziribert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/7:  84%|████████▍ | 203/241 [01:53<00:21,  1.78it/s, loss=0.463]"
          ]
        }
      ],
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run experiments with DziriBERT within a 12-hour limit.\"\"\"\n",
        "    # Define parameters\n",
        "    file_path = '/content/drive/MyDrive/arabic_fake_news/FASSILA/cleaned_data.csv'\n",
        "    save_dir = '/content/drive/MyDrive/arabic_fake_news/FASSILA/'\n",
        "    results_path = os.path.join(save_dir, \"02_experiment_results_DziriBERT.csv\")\n",
        "\n",
        "    batch_sizes = [8, 16, 32]\n",
        "    num_epochs_list = [3, 5, 7]\n",
        "    max_lengths = [64, 128, 256]\n",
        "    learning_rates = [1e-5, 2e-5, 5e-5]\n",
        "    class_weights_list = [[1.0, 1.0], [2.0, 1.0], [1.0, 2.0]]\n",
        "\n",
        "    # Load data once\n",
        "    df = load_and_visualize_data(file_path)\n",
        "    dataset_size = len(df)\n",
        "\n",
        "    # System information\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    torch_version = torch.__version__\n",
        "    transformers_version = transformers.__version__\n",
        "\n",
        "    # Results storage\n",
        "    results = []\n",
        "    save_interval = 10  # Save results every 10 experiments\n",
        "    max_runtime = 12 * 3600  # 12 hours in seconds\n",
        "    start_global_time = time.time()\n",
        "\n",
        "    # Track unique experiment configurations\n",
        "    tested_configs = set()\n",
        "\n",
        "    num_layers = 12\n",
        "    layer_indices = list(range(num_layers))\n",
        "\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        if time.time() - start_global_time > max_runtime:\n",
        "            print(\"Time limit reached (12 hours). Stopping experiments.\")\n",
        "            break  # Stop if 12 hours exceeded\n",
        "\n",
        "        # Randomly select hyperparameters\n",
        "        batch_size = random.choice(batch_sizes)\n",
        "        num_epochs = random.choice(num_epochs_list)\n",
        "        max_length = random.choice(max_lengths)\n",
        "        lr = random.choice(learning_rates)\n",
        "        class_weights = random.choice(class_weights_list)\n",
        "\n",
        "        # Randomly select trainable layers (1 to 6 layers frozen randomly)\n",
        "        num_trainable = random.randint(1, 6)\n",
        "        frozen_layers = tuple(sorted(random.sample(layer_indices, num_trainable)))\n",
        "\n",
        "        # Create a unique key for this configuration\n",
        "        config_key = (batch_size, num_epochs, max_length, lr, str(class_weights), frozen_layers)\n",
        "\n",
        "        # Skip if this configuration was tested before\n",
        "        if config_key in tested_configs:\n",
        "            continue\n",
        "\n",
        "        # Mark this configuration as tested\n",
        "        tested_configs.add(config_key)\n",
        "\n",
        "        layer_control = {i: (i not in frozen_layers) for i in range(num_layers)}\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Data processing\n",
        "            train_tokens, test_tokens, train_labels, test_labels = split_and_tokenize_data(df, max_length=max_length)\n",
        "            train_dataloader, test_dataloader = create_dataloaders(train_tokens, test_tokens, train_labels, test_labels, batch_size)\n",
        "\n",
        "            # Model setup\n",
        "            model, device = setup_model_and_device(layer_control=layer_control)\n",
        "\n",
        "            # Training setup\n",
        "            optimizer, lr_scheduler, criterion = setup_training_components(model, train_dataloader, num_epochs, lr, class_weights, device)\n",
        "\n",
        "            # Training\n",
        "            train_model(model, train_dataloader, optimizer, criterion, lr_scheduler, device, num_epochs)\n",
        "\n",
        "            # Evaluation\n",
        "            accuracy, roc_auc = evaluate_model(model, test_dataloader, device)\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            # Store results for this iteration\n",
        "            result = {\n",
        "                'iteration': iteration,\n",
        "                'dataset_path': file_path,\n",
        "                'dataset_size': dataset_size,\n",
        "                'batch_size': batch_size,\n",
        "                'num_epochs': num_epochs,\n",
        "                'max_length': max_length,\n",
        "                'learning_rate': lr,\n",
        "                'class_weights': str(class_weights),\n",
        "                'trainable_layers': str(frozen_layers),\n",
        "                'num_trainable_layers': num_trainable,\n",
        "                'device': str(device),\n",
        "                'cuda_available': cuda_available,\n",
        "                'torch_version': torch_version,\n",
        "                'transformers_version': transformers_version,\n",
        "                'execution_time': elapsed_time,\n",
        "                'accuracy': accuracy,\n",
        "                'roc_auc': roc_auc\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Minimal printing\n",
        "            print(\"Iteration:\", iteration)\n",
        "            print(result)\n",
        "            print(\"--------------------------------------------------\")\n",
        "\n",
        "            # Save periodically\n",
        "            if len(results) % save_interval == 0:\n",
        "                pd.DataFrame(results).to_csv(results_path, index=False)\n",
        "            iteration += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error in iteration {iteration}: {str(e)}\")\n",
        "\n",
        "    # Final Save\n",
        "    pd.DataFrame(results).to_csv(results_path, index=False)\n",
        "    print(\"\\nAll experiments completed!\")\n",
        "    print(f\"Final results saved to {results_path}\")\n",
        "    print(\"Top 5 results sorted by accuracy:\")\n",
        "    print(pd.DataFrame(results).sort_values(by='accuracy', ascending=False).head(5))\n",
        "\n",
        "# Run the pipeline\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}